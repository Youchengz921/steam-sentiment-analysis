import streamlit as st
import requests
import pandas as pd
from transformers import pipeline
import plotly.express as px
import os

# --- é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="Steam è©•è«– AI åˆ†æå™¨ Pro", layout="wide", page_icon="ğŸ®")

# --- 1. è¼‰å…¥ AI æ¨¡å‹ (å¿«å–å„ªåŒ–) ---
@st.cache_resource
def load_models():
    # å„ªå…ˆè¼‰å…¥å¾®èª¿å¾Œçš„æ¨¡å‹
    local_model_path = "./fine_tuned_model"
    
    if os.path.exists(local_model_path):
        print(f"ğŸ“¦ è¼‰å…¥å¾®èª¿æ¨¡å‹: {local_model_path}")
        sentiment_analyzer = pipeline(
            "sentiment-analysis", 
            model=local_model_path,
            top_k=None
        )
    else:
        print("âš ï¸ æœªæ‰¾åˆ°å¾®èª¿æ¨¡å‹ï¼Œä½¿ç”¨é è¨­æ¨¡å‹")
        sentiment_analyzer = pipeline(
            "sentiment-analysis", 
            model="distilbert-base-uncased-finetuned-sst-2-english",
            top_k=None
        )
    return sentiment_analyzer

sentiment_analyzer = load_models()

# --- 2. å·¥å…·å‡½å¼ï¼šæœå°‹éŠæˆ² ID ---
def get_game_id(game_name):
    try:
        url = "https://store.steampowered.com/api/storesearch/"
        params = {'term': game_name, 'l': 'english', 'cc': 'US'}
        r = requests.get(url, params=params)
        data = r.json()
        if data['total'] > 0:
            item = data['items'][0]
            return item['id'], item['name'], item.get('tiny_image', '')
        return None, None, None
    except Exception as e:
        return None, None, None

# --- 3. å·¥å…·å‡½å¼ï¼šæŠ“å–è©•è«– (å¸¶é€²åº¦é¡¯ç¤º) ---
def fetch_reviews_with_progress(app_id, limit=100, language='english', status_obj=None):
    """
    ä½¿ç”¨ Steam API æ‰‹å‹•åˆ†é æŠ“å–è©•è«–ï¼Œæ”¯æ´å³æ™‚é¡¯ç¤ºä¸‹è¼‰é€²åº¦ã€‚
    language='all' æ™‚æœƒåˆ†åˆ¥æŠ“å– english, schinese, tchinese
    """
    reviews_data = []
    
    # å¦‚æœé¸æ“‡ 'all'ï¼Œåˆ†åˆ¥æŠ“å–ä¸‰ç¨®èªè¨€
    if language == 'all':
        languages = ['english', 'schinese', 'tchinese']
        per_lang_limit = limit // 3
        for lang in languages:
            if status_obj:
                status_obj.update(label=f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ {lang} è©•è«–...")
            lang_reviews = fetch_single_language(app_id, per_lang_limit, lang, status_obj)
            reviews_data.extend(lang_reviews)
        return reviews_data
    else:
        return fetch_single_language(app_id, limit, language, status_obj)

def fetch_single_language(app_id, limit, language, status_obj=None):
    """æŠ“å–å–®ä¸€èªè¨€çš„è©•è«–"""
    reviews_data = []
    cursor = '*'
    seen_texts = {}  # ç”¨æ–¼è¿½è¹¤é‡è¤‡è©•è«–
    
    base_url = f"https://store.steampowered.com/appreviews/{app_id}"
    
    while len(reviews_data) < limit:
        params = {
            'json': 1,
            'language': language,
            'filter': 'recent',
            'num_per_page': min(100, limit - len(reviews_data)),
            'cursor': cursor,
            'purchase_type': 'all'
        }
        
        try:
            response = requests.get(base_url, params=params, timeout=30)
            data = response.json()
            
            if not data.get('success') or 'reviews' not in data:
                break
            
            reviews = data['reviews']
            if not reviews:
                break  # æ²’æœ‰æ›´å¤šè©•è«–äº†
            
            for r in reviews:
                if len(reviews_data) >= limit:
                    break
                    
                review_text = r.get('review', '')
                
                # è³‡æ–™æ¸…æ´—ï¼šå¦‚æœæ˜¯ç©ºå­—ä¸²ï¼Œå°±è·³é
                if not review_text or len(str(review_text).strip()) == 0:
                    continue
                
                # éæ¿¾é‡è¤‡è©•è«–ï¼ˆåŒæ¨£å…§å®¹æœ€å¤š 5 å‰‡ï¼‰
                text_key = review_text[:100]  # ç”¨å‰100å­—ä½œç‚ºkey
                if text_key in seen_texts:
                    seen_texts[text_key] += 1
                    if seen_texts[text_key] > 5:
                        continue
                else:
                    seen_texts[text_key] = 1
                
                reviews_data.append({
                    'text': review_text,
                    'votes_up': r.get('votes_up', 0),
                    'author_playtime': r.get('author', {}).get('playtime_forever', 0) // 60
                })
            
            # æ›´æ–°é€²åº¦é¡¯ç¤º (ä½¿ç”¨ status.update æ›´æ–°æ¨™ç±¤)
            if status_obj:
                status_obj.update(label=f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰è©•è«–... ({len(reviews_data)}/{limit})")
            
            # å–å¾—ä¸‹ä¸€é çš„ cursor
            cursor = data.get('cursor')
            if not cursor:
                break
                
        except Exception as e:
            if status_obj:
                status_obj.write(f"âš ï¸ ä¸‹è¼‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            break
    
    return reviews_data

# å¿«å–ç‰ˆæœ¬ (ç”¨æ–¼å„²å­˜å·²ä¸‹è¼‰çš„è³‡æ–™)
@st.cache_data(ttl=86400, show_spinner=False)
def fetch_reviews_cached(app_id, limit=100, language='english'):
    """å¿«å–ç‰ˆæœ¬ï¼Œä¸é¡¯ç¤ºé€²åº¦ä½†æœƒå„²å­˜çµæœ"""
    return fetch_reviews_with_progress(app_id, limit, language, None)

# --- å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šé¢æ¿")
    target_language = st.selectbox("è©•è«–èªè¨€", ["all", "english", "schinese", "tchinese"], index=0, help="é¸æ“‡ 'all' ä»¥æŠ“å–æ‰€æœ‰èªè¨€çš„è©•è«– (åŒ…å«ä¸­æ–‡)")
    review_count = st.slider("æŠ“å–è©•è«–æ•¸é‡", min_value=50, max_value=5000, value=200, step=50)
    st.info("ğŸ’¡ æç¤ºï¼šæ•¸é‡è¶Šå¤šï¼ŒAI åˆ†ææ™‚é–“æœƒè¶Šé•·ã€‚é¸æ“‡ 'all' å¯ä»¥æŠ“åˆ°æœ€å¤šè³‡æ–™ã€‚")
    
    st.divider()
    st.subheader("ğŸ—„ï¸ å¿«å–ç®¡ç†")
    st.caption("è©•è«–è³‡æ–™æœƒå¿«å– 24 å°æ™‚ï¼Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•å¯æ‰‹å‹•æ¸…é™¤å¿«å–ä»¥é‡æ–°ä¸‹è¼‰ã€‚")
    if st.button("ğŸ—‘ï¸ æ¸…é™¤è©•è«–å¿«å–", width="stretch"):
        fetch_reviews_cached.clear()  # æ¸…é™¤å¿«å–
        st.success("âœ… å¿«å–å·²æ¸…é™¤ï¼ä¸‹æ¬¡åˆ†ææ™‚æœƒé‡æ–°ä¸‹è¼‰è©•è«–ã€‚")

# --- ä¸»ç¨‹å¼ä»‹é¢ ---
st.title("ğŸ® Steam è©•è«– AI åˆ†æå™¨ Pro")
st.markdown("### é‹ç”¨ NLP æŠ€è¡“ï¼Œä¸€éµæ´å¯Ÿç©å®¶çœŸå¯¦åé¥‹")

# æœå°‹å€å¡Š
col_search, col_btn = st.columns([4, 1])
with col_search:
    game_name_input = st.text_input("è¼¸å…¥éŠæˆ²åç¨± (è‹±æ–‡)", placeholder="ä¾‹å¦‚: Palworld, Elden Ring")
with col_btn:
    st.write("") # æ’ç‰ˆä½”ä½ç”¨
    st.write("")
    analyze_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", width="stretch")

if analyze_btn and game_name_input:
    # 1. æœå°‹éŠæˆ²
    with st.spinner(f"æ­£åœ¨æœå°‹ '{game_name_input}' ..."):
        app_id, official_name, img_url = get_game_id(game_name_input)
    
    if not app_id:
        st.error("âŒ æ‰¾ä¸åˆ°è©²éŠæˆ²ï¼Œè«‹æª¢æŸ¥æ‹¼å­— (è«‹è¼¸å…¥è‹±æ–‡åç¨±)ã€‚")
    else:
        # é¡¯ç¤ºéŠæˆ²è³‡è¨Š
        st.divider()
        head_col1, head_col2 = st.columns([1, 5])
        with head_col1:
            if img_url:
                st.image(img_url)
        with head_col2:
            st.subheader(f"{official_name} (ID: {app_id})")
            st.caption(f"æ­£åœ¨åˆ†ææœ€è¿‘çš„ {review_count} æ¢è©•è«–...")

        # ä½¿ç”¨ st.status ä¾†åŒ…è£æ•´å€‹éç¨‹ï¼Œè®“ä½¿ç”¨è€…çŸ¥é“é€²åº¦
        with st.status("ğŸš€ æ­£åœ¨åŸ·è¡Œä»»å‹™...", expanded=True) as status:
            
            # 2. æŠ“å–è³‡æ–™ (ä½¿ç”¨å¿«å–)
            reviews_data = fetch_reviews_cached(app_id, limit=review_count, language=target_language)
            
            if not reviews_data:
                # å¿«å–æ²’è³‡æ–™ï¼Œå˜—è©¦å³æ™‚ä¸‹è¼‰
                status.write("ğŸ“¥ å¿«å–ç„¡è³‡æ–™ï¼Œæ­£åœ¨ä¸‹è¼‰...")
                reviews_data = fetch_reviews_with_progress(app_id, limit=review_count, language=target_language, status_obj=status)
            
            if not reviews_data:
                status.update(label="âš ï¸ ä»»å‹™ä¸­æ­¢ï¼šç„¡æ³•æŠ“å–æ•¸æ“š", state="error")
                st.warning("âš ï¸ ç„¡æ³•æŠ“å–åˆ°è¶³å¤ çš„è©•è«–æ•¸æ“šã€‚")
            else:
                status.write(f"âœ… å·²æˆåŠŸæŠ“å– {len(reviews_data)} æ¢è©•è«–ã€‚")
                
                # --- AI åˆ†æéšæ®µ (æ‰¹æ¬¡è™•ç†å„ªåŒ–) ---
                import time
                import math

                texts = [r['text'] for r in reviews_data]
                total_reviews = len(texts)
                BATCH_SIZE = 10 
                
                status.write("ğŸ¤– AI æ­£åœ¨é–±è®€ä¸¦åˆ†æè©•è«–ä¸­...")
                progress_bar = st.progress(0)
                # progress_text = st.empty() # æ”¹ç”¨ progress_bar çš„ caption æˆ–è€…ç›´æ¥åœ¨ status é¡¯ç¤º
                
                predictions = []
                start_time = time.time()
                
                # æ‰¹æ¬¡æ¨è«–è¿´åœˆ
                num_batches = math.ceil(total_reviews / BATCH_SIZE)
                
                for i in range(num_batches):
                    batch_start = i * BATCH_SIZE
                    batch_end = min((i + 1) * BATCH_SIZE, total_reviews)
                    batch_texts = texts[batch_start:batch_end]
                    
                    # åŸ·è¡Œæ¨è«–
                    batch_preds = sentiment_analyzer(batch_texts, truncation=True, max_length=512)
                    predictions.extend(batch_preds)
                    
                    # è¨ˆç®—é€²åº¦
                    current_count = batch_end
                    progress = current_count / total_reviews
                    
                    # è¨ˆç®—æ™‚é–“èˆ‡ ETA
                    elapsed_time = time.time() - start_time
                    avg_time_per_item = elapsed_time / current_count if current_count > 0 else 0
                    remaining_items = total_reviews - current_count
                    eta_seconds = remaining_items * avg_time_per_item
                    
                    # æ›´æ–°é€²åº¦æ¢èˆ‡æ–‡å­—
                    progress_bar.progress(progress, text=f"é€²åº¦: {int(progress*100)}% ({current_count}/{total_reviews}) - é ä¼°å‰©é¤˜: {eta_seconds:.0f}s")
                
                total_time = time.time() - start_time
                status.write(f"âœ… AI åˆ†æå®Œæˆï¼å…±è€—æ™‚ {total_time:.1f} ç§’")
                status.update(label="ğŸš€ åˆ†æå®Œæˆï¼", state="complete", expanded=False)
                time.sleep(1) 
                progress_bar.empty()
            
                # æ•´ç†çµæœ
                final_results = []
                positive_count = 0
                
                for i, pred in enumerate(predictions):
                    # æ‰¾å‡ºåˆ†æ•¸æœ€é«˜çš„æ¨™ç±¤
                    best_label = max(pred, key=lambda x: x['score'])
                    label = best_label['label']
                    score = best_label['score']
                    
                    is_positive = label == 'POSITIVE'
                    if is_positive:
                        positive_count += 1
                    
                    final_results.append({
                        "è©•è«–å…§å®¹": texts[i],
                        "AI åˆ¤æ–·": "æ­£é¢ (Good)" if is_positive else "è² é¢ (Bad)",
                        "ä¿¡å¿ƒåˆ†æ•¸": score,
                        "éŠç©æ™‚æ•¸(hr)": reviews_data[i]['author_playtime'],
                        "æŒ‰è®šæ•¸": reviews_data[i]['votes_up']
                    })
                
                df = pd.DataFrame(final_results)
                
                # --- çµæœå„€è¡¨æ¿ ---
                
                # [å€åŸŸ 1] é—œéµæŒ‡æ¨™ (KPI)
                kpi1, kpi2, kpi3 = st.columns(3)
                pos_rate = (positive_count / len(df)) * 100
                kpi1.metric("ç¸½è©•è«–æ•¸", f"{len(df)} æ¢")
                kpi2.metric("AI å¥½è©•ç‡", f"{pos_rate:.1f}%")
                kpi3.metric("å¹³å‡éŠç©æ™‚æ•¸", f"{df['éŠç©æ™‚æ•¸(hr)'].mean():.1f} å°æ™‚")
                
                st.divider()
                
                # [å€åŸŸ 2] åœ–è¡¨å€
                # åœ–è¡¨å€
                st.subheader("ğŸ“Š å¥½å£è©•æ¯”åˆ†ä½ˆ")
                fig_pie = px.pie(
                    df, 
                    names="AI åˆ¤æ–·", 
                    color="AI åˆ¤æ–·",
                    color_discrete_map={"æ­£é¢ (Good)": "#66c2a5", "è² é¢ (Bad)": "#ef553b"},
                    hole=0.4
                )
                st.plotly_chart(fig_pie, width="stretch")


                
                # [å€åŸŸ 4] è©³ç´°è³‡æ–™è¡¨
                with st.expander("é»æ“ŠæŸ¥çœ‹è©³ç´°è©•è«–æ•¸æ“šè¡¨"):
                    st.dataframe(df, width="stretch")
